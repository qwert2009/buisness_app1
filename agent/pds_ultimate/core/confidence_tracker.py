"""
PDS-Ultimate Confidence & Uncertainty Tracker (Part 10 â€” Item 6)
==================================================================
ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ²Ñ‹Ğ²Ğ¾Ğ´ ÑĞ¾Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ¶Ğ´Ğ°ĞµÑ‚ÑÑ Ğ¾Ñ†ĞµĞ½ĞºĞ¾Ğ¹ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸.
Ğ•ÑĞ»Ğ¸ Ğ½Ğ¸Ğ·ĞºĞ°Ñ â†’ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº.

ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹:
1. ConfidenceEstimator â€” Ğ¾Ñ†ĞµĞ½ĞºĞ° ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°
2. UncertaintyTracker â€” Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ½ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸
3. AutoSearchTrigger â€” Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ´Ğ¾Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ñ€Ğ¸ Ğ½Ğ¸Ğ·ĞºĞ¾Ğ¹ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸
4. ConfidenceCalibrator â€” ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸
5. OutputWrapper â€” Ğ¾Ğ±Ñ‘Ñ€Ñ‚ĞºĞ° Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ñ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸
"""

from __future__ import annotations

import time
from collections import defaultdict
from dataclasses import dataclass, field
from enum import Enum
from typing import Any

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENUMS & DATA MODELS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class ConfidenceLevel(str, Enum):
    """Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸."""
    VERY_HIGH = "very_high"   # > 0.9
    HIGH = "high"             # 0.7 - 0.9
    MEDIUM = "medium"         # 0.5 - 0.7
    LOW = "low"               # 0.3 - 0.5
    VERY_LOW = "very_low"     # < 0.3


class UncertaintyType(str, Enum):
    """Ğ¢Ğ¸Ğ¿ Ğ½ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸."""
    DATA_MISSING = "data_missing"          # ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    CONFLICTING_SOURCES = "conflicting"    # ĞŸÑ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ñ€ĞµÑ‡Ğ¸Ğ²Ñ‹Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸
    OUTDATED_INFO = "outdated"             # Ğ£ÑÑ‚Ğ°Ñ€ĞµĞ²ÑˆĞ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ
    AMBIGUOUS_QUERY = "ambiguous"          # ĞĞµĞ¾Ğ´Ğ½Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
    LOW_SOURCE_TRUST = "low_trust"         # ĞĞ¸Ğ·ĞºĞ¾Ğµ Ğ´Ğ¾Ğ²ĞµÑ€Ğ¸Ğµ Ğº Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°Ğ¼
    INSUFFICIENT_EVIDENCE = "insufficient"  # ĞœĞ°Ğ»Ğ¾ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²
    MODEL_UNCERTAINTY = "model"            # ĞĞµÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸


class SearchAction(str, Enum):
    """Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ Ğ¿Ñ€Ğ¸ Ğ½Ğ¸Ğ·ĞºĞ¾Ğ¹ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸."""
    NONE = "none"
    EXPAND_QUERY = "expand_query"
    ADD_SOURCES = "add_sources"
    VERIFY_FACTS = "verify_facts"
    FULL_RESEARCH = "full_research"


@dataclass
class ConfidenceScore:
    """ĞÑ†ĞµĞ½ĞºĞ° ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°."""
    value: float                # 0.0 - 1.0
    level: ConfidenceLevel = ConfidenceLevel.MEDIUM
    factors: dict[str, float] = field(default_factory=dict)
    uncertainties: list[UncertaintyType] = field(default_factory=list)
    suggested_action: SearchAction = SearchAction.NONE
    explanation: str = ""
    timestamp: float = field(default_factory=time.time)

    def __post_init__(self):
        self.value = max(0.0, min(1.0, self.value))
        self.level = self._compute_level()
        if not self.suggested_action or self.suggested_action == SearchAction.NONE:
            self.suggested_action = self._suggest_action()

    def _compute_level(self) -> ConfidenceLevel:
        if self.value > 0.9:
            return ConfidenceLevel.VERY_HIGH
        elif self.value > 0.7:
            return ConfidenceLevel.HIGH
        elif self.value > 0.5:
            return ConfidenceLevel.MEDIUM
        elif self.value > 0.3:
            return ConfidenceLevel.LOW
        return ConfidenceLevel.VERY_LOW

    def _suggest_action(self) -> SearchAction:
        if self.value > 0.7:
            return SearchAction.NONE
        if UncertaintyType.DATA_MISSING in self.uncertainties:
            return SearchAction.FULL_RESEARCH
        if UncertaintyType.CONFLICTING_SOURCES in self.uncertainties:
            return SearchAction.VERIFY_FACTS
        if UncertaintyType.OUTDATED_INFO in self.uncertainties:
            return SearchAction.ADD_SOURCES
        if self.value < 0.3:
            return SearchAction.FULL_RESEARCH
        return SearchAction.EXPAND_QUERY

    @property
    def needs_additional_search(self) -> bool:
        return self.value < 0.7

    @property
    def emoji(self) -> str:
        emojis = {
            ConfidenceLevel.VERY_HIGH: "ğŸŸ¢",
            ConfidenceLevel.HIGH: "ğŸŸ¡",
            ConfidenceLevel.MEDIUM: "ğŸŸ ",
            ConfidenceLevel.LOW: "ğŸ”´",
            ConfidenceLevel.VERY_LOW: "âš«",
        }
        return emojis.get(self.level, "â“")

    def to_dict(self) -> dict:
        return {
            "value": round(self.value, 3),
            "level": self.level.value,
            "factors": {k: round(v, 3) for k, v in self.factors.items()},
            "uncertainties": [u.value for u in self.uncertainties],
            "action": self.suggested_action.value,
            "needs_search": self.needs_additional_search,
            "explanation": self.explanation,
        }


@dataclass
class TrackedOutput:
    """Ğ’Ñ‹Ğ²Ğ¾Ğ´ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ñ Ñ‚Ñ€ĞµĞºĞ¸Ğ½Ğ³Ğ¾Ğ¼ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸."""
    content: str
    confidence: ConfidenceScore
    query: str = ""
    sources_count: int = 0
    search_iterations: int = 0
    total_time_ms: float = 0.0
    metadata: dict = field(default_factory=dict)

    def format_with_confidence(self) -> str:
        """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ñ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸."""
        conf = self.confidence
        lines = [self.content]
        lines.append(
            f"\n{conf.emoji} Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ: {conf.value:.0%} ({conf.level.value})"
        )
        if conf.uncertainties:
            labels = [u.value for u in conf.uncertainties]
            lines.append(f"âš ï¸ ĞĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸: {', '.join(labels)}")
        if self.sources_count:
            lines.append(f"ğŸ“– Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²: {self.sources_count}")
        if self.search_iterations > 1:
            lines.append(f"ğŸ”„ Ğ˜Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞºĞ°: {self.search_iterations}")
        return "\n".join(lines)

    def to_dict(self) -> dict:
        return {
            "content": self.content[:500],
            "confidence": self.confidence.to_dict(),
            "sources_count": self.sources_count,
            "search_iterations": self.search_iterations,
            "time_ms": round(self.total_time_ms, 1),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. CONFIDENCE ESTIMATOR â€” ĞÑ†ĞµĞ½ĞºĞ° ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class ConfidenceEstimator:
    """
    ĞÑ†ĞµĞ½ĞºĞ° ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ° Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¾Ğ².

    Ğ¤Ğ°ĞºÑ‚Ğ¾Ñ€Ñ‹:
    - source_count: ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²
    - source_agreement: ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²
    - data_freshness: ÑĞ²ĞµĞ¶ĞµÑÑ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    - query_specificity: Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°
    - evidence_strength: ÑĞ¸Ğ»Ğ° Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²
    """

    # Ğ’ĞµÑa Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¾Ğ²
    FACTOR_WEIGHTS: dict[str, float] = {
        "source_count": 0.20,
        "source_agreement": 0.25,
        "data_freshness": 0.15,
        "query_specificity": 0.15,
        "evidence_strength": 0.25,
    }

    def estimate(
        self,
        text: str = "",
        source_count: int = 0,
        source_agreement: float = 1.0,
        data_freshness: float = 1.0,
        query_specificity: float = 0.5,
        evidence_strength: float = 0.5,
        custom_factors: dict[str, float] | None = None,
    ) -> ConfidenceScore:
        """
        ĞÑ†ĞµĞ½Ğ¸Ñ‚ÑŒ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ.

        Args:
            text: Ğ¢ĞµĞºÑÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°
            source_count: ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ² (0-10+)
            source_agreement: Ğ¡Ğ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ (0-1)
            data_freshness: Ğ¡Ğ²ĞµĞ¶ĞµÑÑ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (0-1)
            query_specificity: Ğ¢Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° (0-1)
            evidence_strength: Ğ¡Ğ¸Ğ»Ğ° Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ² (0-1)
        """
        factors: dict[str, float] = {}

        # Source count â†’ normalized (0-1)
        factors["source_count"] = min(
            1.0, source_count / 5.0) if source_count > 0 else 0.1
        factors["source_agreement"] = max(0.0, min(1.0, source_agreement))
        factors["data_freshness"] = max(0.0, min(1.0, data_freshness))
        factors["query_specificity"] = max(0.0, min(1.0, query_specificity))
        factors["evidence_strength"] = max(0.0, min(1.0, evidence_strength))

        if custom_factors:
            factors.update(custom_factors)

        weighted_sum = sum(
            factors.get(k, 0.5) * w
            for k, w in self.FACTOR_WEIGHTS.items()
        )

        # Ğ¢ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· â€” hedging words ÑĞ½Ğ¸Ğ¶Ğ°ÑÑ‚ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ
        text_penalty = self._analyze_text_confidence(text)

        final = weighted_sum * text_penalty

        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ uncertainties
        uncertainties: list[UncertaintyType] = []
        if source_count == 0:
            uncertainties.append(UncertaintyType.DATA_MISSING)
        if source_agreement < 0.5:
            uncertainties.append(UncertaintyType.CONFLICTING_SOURCES)
        if data_freshness < 0.3:
            uncertainties.append(UncertaintyType.OUTDATED_INFO)
        if query_specificity < 0.3:
            uncertainties.append(UncertaintyType.AMBIGUOUS_QUERY)
        if evidence_strength < 0.3:
            uncertainties.append(UncertaintyType.INSUFFICIENT_EVIDENCE)

        explanation_parts = []
        if factors["source_count"] < 0.4:
            explanation_parts.append("Ğ¼Ğ°Ğ»Ğ¾ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²")
        if factors["source_agreement"] < 0.5:
            explanation_parts.append("Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸ Ñ€Ğ°ÑÑ…Ğ¾Ğ´ÑÑ‚ÑÑ")
        if factors["data_freshness"] < 0.5:
            explanation_parts.append("Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ ÑƒÑÑ‚Ğ°Ñ€ĞµĞ²ÑˆĞ¸Ğ¼Ğ¸")
        if not explanation_parts:
            explanation_parts.append("Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")

        return ConfidenceScore(
            value=final,
            factors=factors,
            uncertainties=uncertainties,
            explanation="; ".join(explanation_parts),
        )

    @staticmethod
    def _analyze_text_confidence(text: str) -> float:
        """ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ…ĞµĞ´Ğ¶Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ñ… ÑĞ»Ğ¾Ğ² Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ â†’ penalty multiplier."""
        if not text:
            return 0.9
        text_lower = text.lower()
        hedging_words = [
            "Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾", "Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾", "Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ", "Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾",
            "Ğ½Ğµ ÑƒĞ²ĞµÑ€ĞµĞ½", "perhaps", "maybe", "probably", "might",
            "uncertain", "unclear", "Ğ½Ğµ ÑÑĞ½Ğ¾", "Ñ‚Ñ€ÑƒĞ´Ğ½Ğ¾ ÑĞºĞ°Ğ·Ğ°Ñ‚ÑŒ",
            "Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ñ‡Ğ½Ğ¾", "Ğ¿Ñ€Ğ¸Ğ±Ğ»Ğ¸Ğ·Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾", "Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾",
        ]
        strong_words = [
            "Ñ‚Ğ¾Ñ‡Ğ½Ğ¾", "Ğ¾Ğ´Ğ½Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ½Ğ¾", "Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾", "exactly",
            "definitely", "certainly", "Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¾", "verified",
            "Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ğ½Ğ¾", "proved",
        ]
        hedge_count = sum(1 for w in hedging_words if w in text_lower)
        strong_count = sum(1 for w in strong_words if w in text_lower)

        penalty = 1.0 - hedge_count * 0.05 + strong_count * 0.03
        return max(0.5, min(1.1, penalty))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. UNCERTAINTY TRACKER â€” ĞÑ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class UncertaintyTracker:
    """
    ĞÑ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ½ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼.
    Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ´Ğ»Ñ ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ¸.
    """

    def __init__(self, max_history: int = 1000):
        self._history: list[ConfidenceScore] = []
        self._by_type: defaultdict[str, int] = defaultdict(int)
        self._max_history = max_history
        self._action_outcomes: list[dict] = []  # {action, success}

    def track(self, score: ConfidenceScore) -> None:
        """Ğ—Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ¾Ñ†ĞµĞ½ĞºÑƒ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸."""
        self._history.append(score)
        if len(self._history) > self._max_history:
            self._history = self._history[-self._max_history // 2:]
        for u in score.uncertainties:
            self._by_type[u.value] += 1

    def record_outcome(
        self,
        action: SearchAction,
        success: bool,
        confidence_before: float,
        confidence_after: float,
    ) -> None:
        """Ğ—Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ."""
        self._action_outcomes.append({
            "action": action.value,
            "success": success,
            "delta": confidence_after - confidence_before,
            "timestamp": time.time(),
        })

    @property
    def average_confidence(self) -> float:
        if not self._history:
            return 0.5
        return sum(s.value for s in self._history) / len(self._history)

    @property
    def low_confidence_rate(self) -> float:
        if not self._history:
            return 0.0
        low = sum(1 for s in self._history if s.value < 0.5)
        return low / len(self._history)

    def get_most_common_uncertainties(self, top_n: int = 5) -> list[tuple[str, int]]:
        """ĞĞ°Ğ¸Ğ±Ğ¾Ğ»ĞµĞµ Ñ‡Ğ°ÑÑ‚Ñ‹Ğµ Ñ‚Ğ¸Ğ¿Ñ‹ Ğ½ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸."""
        return sorted(
            self._by_type.items(),
            key=lambda x: x[1],
            reverse=True,
        )[:top_n]

    def get_action_effectiveness(self) -> dict[str, dict]:
        """Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ."""
        by_action: defaultdict[str, list] = defaultdict(list)
        for outcome in self._action_outcomes:
            by_action[outcome["action"]].append(outcome)

        result = {}
        for action, outcomes in by_action.items():
            successes = sum(1 for o in outcomes if o["success"])
            avg_delta = sum(o["delta"] for o in outcomes) / \
                len(outcomes) if outcomes else 0
            result[action] = {
                "count": len(outcomes),
                "success_rate": round(successes / len(outcomes), 2) if outcomes else 0,
                "avg_improvement": round(avg_delta, 3),
            }
        return result

    def get_stats(self) -> dict:
        return {
            "total_tracked": len(self._history),
            "average_confidence": round(self.average_confidence, 3),
            "low_confidence_rate": round(self.low_confidence_rate, 3),
            "uncertainties": dict(self._by_type),
            "action_outcomes": len(self._action_outcomes),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. AUTO-SEARCH TRIGGER â€” ĞĞ²Ñ‚Ğ¾-Ğ´Ğ¾Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ñ€Ğ¸ Ğ½Ğ¸Ğ·ĞºĞ¾Ğ¹ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class AutoSearchTrigger:
    """
    ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°.

    ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ°:
    - confidence < 0.5 â†’ full_research
    - confidence < 0.7 â†’ expand_query
    - conflicting_sources â†’ verify_facts
    - outdated_info â†’ add_sources
    """

    def __init__(self, threshold: float = 0.7, max_iterations: int = 3):
        self._threshold = threshold
        self._max_iterations = max_iterations
        self._triggers_fired = 0

    def should_search(self, score: ConfidenceScore) -> bool:
        """ĞÑƒĞ¶ĞµĞ½ Ğ»Ğ¸ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº?"""
        return score.value < self._threshold

    def get_search_plan(
        self,
        score: ConfidenceScore,
        iteration: int = 0,
    ) -> dict | None:
        """
        ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿Ğ»Ğ°Ğ½ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°.

        Returns: {action, params} Ğ¸Ğ»Ğ¸ None
        """
        if iteration >= self._max_iterations:
            return None
        if not self.should_search(score):
            return None

        self._triggers_fired += 1
        action = score.suggested_action

        plan: dict[str, Any] = {
            "action": action.value, "iteration": iteration + 1}

        if action == SearchAction.FULL_RESEARCH:
            plan["max_sources"] = 5 + iteration * 2
            plan["expand_queries"] = True
        elif action == SearchAction.ADD_SOURCES:
            plan["max_sources"] = 3 + iteration
            plan["prefer_recent"] = True
        elif action == SearchAction.VERIFY_FACTS:
            plan["verify_mode"] = True
            plan["min_trust"] = 0.7
        elif action == SearchAction.EXPAND_QUERY:
            plan["expansions"] = 2 + iteration

        return plan

    @property
    def threshold(self) -> float:
        return self._threshold

    @threshold.setter
    def threshold(self, value: float) -> None:
        self._threshold = max(0.1, min(0.95, value))

    def get_stats(self) -> dict:
        return {
            "threshold": self._threshold,
            "max_iterations": self._max_iterations,
            "triggers_fired": self._triggers_fired,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. CONFIDENCE CALIBRATOR â€” ĞšĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ° Ğ½Ğ° Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class ConfidenceCalibrator:
    """
    ĞšĞ°Ğ»Ğ¸Ğ±Ñ€ÑƒĞµÑ‚ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….

    Ğ•ÑĞ»Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿ĞµÑ€ĞµĞ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚/Ğ½ĞµĞ´Ğ¾Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ â†’
    ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¸Ñ€ÑƒĞµĞ¼.
    """

    def __init__(self):
        # (predicted, actual_correct)
        self._predictions: list[tuple[float, bool]] = []
        self._calibration_factor: float = 1.0

    def record(self, predicted_confidence: float, was_correct: bool) -> None:
        """Ğ—Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚."""
        self._predictions.append((predicted_confidence, was_correct))
        if len(self._predictions) > 500:
            self._predictions = self._predictions[-250:]
        self._update_calibration()

    def calibrate(self, raw_confidence: float) -> float:
        """ĞÑ‚ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ñ†ĞµĞ½ĞºÑƒ."""
        return max(0.0, min(1.0, raw_confidence * self._calibration_factor))

    def _update_calibration(self) -> None:
        """ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚ ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ¸."""
        if len(self._predictions) < 10:
            return

        bins: defaultdict[int, list[bool]] = defaultdict(list)
        for pred, actual in self._predictions:
            bin_idx = int(pred * 10)
            bins[bin_idx].append(actual)

        predicted_avg = sum(p for p, _ in self._predictions) / \
            len(self._predictions)
        actual_avg = sum(1 for _, a in self._predictions if a) / \
            len(self._predictions)

        if predicted_avg > 0:
            self._calibration_factor = actual_avg / predicted_avg
            self._calibration_factor = max(
                0.5, min(1.5, self._calibration_factor))

    @property
    def is_overconfident(self) -> bool:
        return self._calibration_factor < 0.9

    @property
    def is_underconfident(self) -> bool:
        return self._calibration_factor > 1.1

    def get_stats(self) -> dict:
        total = len(self._predictions)
        correct = sum(1 for _, a in self._predictions if a)
        return {
            "total_predictions": total,
            "accuracy": round(correct / total, 3) if total > 0 else 0.0,
            "calibration_factor": round(self._calibration_factor, 3),
            "overconfident": self.is_overconfident,
            "underconfident": self.is_underconfident,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FACADE: ConfidenceTracker
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class ConfidenceTracker:
    """
    Ğ¤Ğ°ÑĞ°Ğ´ Ğ´Ğ»Ñ confidence & uncertainty tracking.

    Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:
        tracker = ConfidenceTracker()

        # ĞÑ†ĞµĞ½Ğ¸Ñ‚ÑŒ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ
        score = tracker.estimate("ĞÑ‚Ğ²ĞµÑ‚ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ", source_count=3)

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ, Ğ½ÑƒĞ¶ĞµĞ½ Ğ»Ğ¸ Ğ´Ğ¾Ğ¿Ğ¾Ğ¸ÑĞº
        if tracker.needs_search(score):
            plan = tracker.get_search_plan(score)

        # ĞĞ±ĞµÑ€Ğ½ÑƒÑ‚ÑŒ Ğ²Ñ‹Ğ²Ğ¾Ğ´
        output = tracker.wrap_output("ĞÑ‚Ğ²ĞµÑ‚", score, query="Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ")
    """

    def __init__(self, auto_search_threshold: float = 0.7):
        self.estimator = ConfidenceEstimator()
        self.uncertainty_tracker = UncertaintyTracker()
        self.auto_search = AutoSearchTrigger(threshold=auto_search_threshold)
        self.calibrator = ConfidenceCalibrator()

    def estimate(
        self,
        text: str = "",
        source_count: int = 0,
        source_agreement: float = 1.0,
        data_freshness: float = 1.0,
        evidence_strength: float = 0.5,
        **kwargs,
    ) -> ConfidenceScore:
        """ĞÑ†ĞµĞ½Ğ¸Ñ‚ÑŒ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°."""
        score = self.estimator.estimate(
            text=text,
            source_count=source_count,
            source_agreement=source_agreement,
            data_freshness=data_freshness,
            evidence_strength=evidence_strength,
            **kwargs,
        )

        calibrated_value = self.calibrator.calibrate(score.value)
        score.value = calibrated_value
        score.level = score._compute_level()

        self.uncertainty_tracker.track(score)
        return score

    def needs_search(self, score: ConfidenceScore) -> bool:
        """ĞÑƒĞ¶ĞµĞ½ Ğ»Ğ¸ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº?"""
        return self.auto_search.should_search(score)

    def get_search_plan(
        self,
        score: ConfidenceScore,
        iteration: int = 0,
    ) -> dict | None:
        """ĞŸĞ»Ğ°Ğ½ Ğ´Ğ¾Ğ¿Ğ¾Ğ¸ÑĞºĞ°."""
        return self.auto_search.get_search_plan(score, iteration)

    def wrap_output(
        self,
        content: str,
        confidence: ConfidenceScore,
        query: str = "",
        sources_count: int = 0,
    ) -> TrackedOutput:
        """ĞĞ±ĞµÑ€Ğ½ÑƒÑ‚ÑŒ Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ñ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸."""
        return TrackedOutput(
            content=content,
            confidence=confidence,
            query=query,
            sources_count=sources_count,
        )

    def record_feedback(self, predicted: float, was_correct: bool) -> None:
        """Ğ—Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½ÑƒÑ ÑĞ²ÑĞ·ÑŒ Ğ´Ğ»Ñ ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ¸."""
        self.calibrator.record(predicted, was_correct)

    def get_stats(self) -> dict:
        return {
            "uncertainty": self.uncertainty_tracker.get_stats(),
            "auto_search": self.auto_search.get_stats(),
            "calibrator": self.calibrator.get_stats(),
        }


# â”€â”€â”€ Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞºĞ·ĞµĞ¼Ğ¿Ğ»ÑÑ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

confidence_tracker = ConfidenceTracker()
