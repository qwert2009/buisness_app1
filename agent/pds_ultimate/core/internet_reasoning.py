"""
PDS-Ultimate Internet Reasoning Layer
=======================================
–°–ª–æ–π –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –ø–æ–≤–µ—Ä—Ö Browser Engine.

–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
1. Multi-source search ‚Äî –ø–æ–∏—Å–∫ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º, –∞–≥—Ä–µ–≥–∞—Ü–∏—è
2. Source trust scoring ‚Äî –æ—Ü–µ–Ω–∫–∞ –¥–æ–≤–µ—Ä–∏—è –∫ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
3. Contradiction detection ‚Äî –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π
4. Fact synthesis ‚Äî —Å–∏–Ω—Ç–µ–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å —Ü–∏—Ç–∞—Ç–∞–º–∏
5. Query expansion ‚Äî —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è
6. Information freshness ‚Äî –æ—Ü–µ–Ω–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
  User Query ‚Üí QueryExpander ‚Üí MultiSourceSearch ‚Üí TrustScorer
  ‚Üí ContradictionDetector ‚Üí FactSynthesizer ‚Üí Structured Answer
"""

from __future__ import annotations

import hashlib
import re
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from urllib.parse import urlparse

from pds_ultimate.config import logger

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# CONSTANTS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# –î–æ–º–µ–Ω—ã —Å –≤—ã—Å–æ–∫–∏–º –¥–æ–≤–µ—Ä–∏–µ–º (–±–∞–∑–æ–≤—ã–π —Å–ø–∏—Å–æ–∫)
TRUSTED_DOMAINS: dict[str, float] = {
    # –≠–Ω—Ü–∏–∫–ª–æ–ø–µ–¥–∏–∏ / —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏
    "wikipedia.org": 0.85,
    "britannica.com": 0.90,
    "scholar.google.com": 0.92,
    # –ù–æ–≤–æ—Å—Ç–∏ (–º–∏—Ä–æ–≤—ã–µ)
    "reuters.com": 0.88,
    "bbc.com": 0.85,
    "bbc.co.uk": 0.85,
    "apnews.com": 0.88,
    # –¢–µ—Ö–Ω–∏–∫–∞ / –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ
    "stackoverflow.com": 0.80,
    "github.com": 0.78,
    "docs.python.org": 0.95,
    "developer.mozilla.org": 0.92,
    "w3.org": 0.95,
    # –ë–∏–∑–Ω–µ—Å / —Ñ–∏–Ω–∞–Ω—Å—ã
    "bloomberg.com": 0.85,
    "forbes.com": 0.75,
    "investopedia.com": 0.80,
    # –ù–∞—É–∫–∞
    "nature.com": 0.93,
    "sciencedirect.com": 0.90,
    "pubmed.ncbi.nlm.nih.gov": 0.92,
    "arxiv.org": 0.85,
    # –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–µ–Ω–Ω—ã–µ
    "gov": 0.88,
    "edu": 0.82,
}

# –î–æ–º–µ–Ω—ã —Å –Ω–∏–∑–∫–∏–º –¥–æ–≤–µ—Ä–∏–µ–º
UNTRUSTED_PATTERNS: list[str] = [
    "reddit.com",
    "quora.com",
    "yahoo.answers",
    "answers.com",
    "wiki.answers",
    "ehow.com",
    "about.com",
]

# –ú–∞—Ä–∫–µ—Ä—ã —Å–≤–µ–∂–µ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
FRESHNESS_PATTERNS: list[re.Pattern] = [
    re.compile(r"(\d{4}[-/]\d{1,2}[-/]\d{1,2})"),          # 2025-01-15
    re.compile(r"(\d{1,2}\s+\w+\s+\d{4})"),                # 15 January 2025
    re.compile(r"(January|February|March|April|May|June|"
               r"July|August|September|October|November|"
               r"December)\s+\d{1,2},?\s+\d{4}", re.I),    # January 15, 2025
    re.compile(r"Updated:?\s*(.{5,30})", re.I),             # Updated: ...
]


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# DATA MODELS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


class SourceReliability(str, Enum):
    """–£—Ä–æ–≤–µ–Ω—å –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞."""
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    UNKNOWN = "unknown"


class ContradictionSeverity(str, Enum):
    """–°–µ—Ä—å—ë–∑–Ω–æ—Å—Ç—å –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è."""
    MINOR = "minor"        # –†–∞–∑–ª–∏—á–∏—è –≤ –¥–µ—Ç–∞–ª—è—Ö
    MODERATE = "moderate"  # –°—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–∞–∑–ª–∏—á–∏—è
    MAJOR = "major"        # –ü—Ä—è–º—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è


@dataclass
class SourceInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ."""
    url: str
    domain: str
    title: str = ""
    trust_score: float = 0.5       # 0.0-1.0
    reliability: SourceReliability = SourceReliability.UNKNOWN
    freshness_score: float = 0.5   # 0.0-1.0 (1.0 = —Å–≤–µ–∂–∏–π)
    content_length: int = 0
    detected_date: str | None = None
    language: str = "unknown"

    @property
    def composite_score(self) -> float:
        """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (trust * freshness)."""
        return round(self.trust_score * 0.7 + self.freshness_score * 0.3, 3)


@dataclass
class ExtractedFact:
    """–ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ñ–∞–∫—Ç —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –∏—Å—Ç–æ—á–Ω–∏–∫—É."""
    text: str
    source: SourceInfo
    confidence: float = 0.5     # 0.0-1.0
    category: str = "general"   # general, price, date, statistic, opinion
    keywords: list[str] = field(default_factory=list)

    @property
    def fact_id(self) -> str:
        """–£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —Ñ–∞–∫—Ç–∞."""
        h = hashlib.md5(self.text.encode()).hexdigest()[:8]
        return f"fact_{h}"


@dataclass
class Contradiction:
    """–ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ –º–µ–∂–¥—É —Ñ–∞–∫—Ç–∞–º–∏."""
    fact_a: ExtractedFact
    fact_b: ExtractedFact
    severity: ContradictionSeverity
    description: str = ""

    @property
    def sources_involved(self) -> list[str]:
        return [self.fact_a.source.url, self.fact_b.source.url]


@dataclass
class SynthesizedAnswer:
    """–°–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤."""
    query: str
    summary: str                            # –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç
    facts: list[ExtractedFact]              # –í—Å–µ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã
    sources: list[SourceInfo]               # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    contradictions: list[Contradiction]     # –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è
    confidence: float                       # –û–±—â–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å 0.0-1.0
    sources_count: int = 0                  # –ö–æ–ª-–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    timestamp: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> dict:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å."""
        return {
            "query": self.query,
            "summary": self.summary,
            "confidence": self.confidence,
            "sources_count": self.sources_count,
            "facts_count": len(self.facts),
            "contradictions_count": len(self.contradictions),
            "sources": [
                {"url": s.url, "domain": s.domain,
                 "trust": s.trust_score, "title": s.title}
                for s in self.sources
            ],
            "contradictions": [
                {"severity": c.severity.value,
                 "description": c.description}
                for c in self.contradictions
            ],
        }

    @property
    def has_contradictions(self) -> bool:
        return len(self.contradictions) > 0

    @property
    def quality_label(self) -> str:
        """–ú–µ—Ç–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞."""
        if self.confidence >= 0.8 and not self.has_contradictions:
            return "‚úÖ –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ"
        elif self.confidence >= 0.5:
            return "‚ö†Ô∏è –°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ"
        else:
            return "‚ùå –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ"


@dataclass
class ResearchStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è."""
    queries_performed: int = 0
    pages_analyzed: int = 0
    facts_extracted: int = 0
    contradictions_found: int = 0
    total_time_ms: int = 0

    def to_dict(self) -> dict:
        return {
            "queries": self.queries_performed,
            "pages": self.pages_analyzed,
            "facts": self.facts_extracted,
            "contradictions": self.contradictions_found,
            "time_ms": self.total_time_ms,
        }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 1. TRUST SCORER ‚Äî –û—Ü–µ–Ω–∫–∞ –¥–æ–≤–µ—Ä–∏—è –∫ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


class TrustScorer:
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç—å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.

    –§–∞–∫—Ç–æ—Ä—ã:
    - –î–æ–º–µ–Ω–Ω–∞—è —Ä–µ–ø—É—Ç–∞—Ü–∏—è (–ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–∞—è + –≤—ã—É—á–µ–Ω–Ω–∞—è)
    - –°–≤–µ–∂–µ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    - –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–∫–æ—Ä–æ—Ç–∫–∏–π = –º–µ–Ω–µ–µ –Ω–∞–¥—ë–∂–Ω—ã–π)
    - HTTPS vs HTTP
    - TLD (.gov, .edu = –≤—ã—Å–æ–∫–∏–π)
    """

    def __init__(self):
        self._domain_scores: dict[str, float] = dict(TRUSTED_DOMAINS)
        self._custom_scores: dict[str, float] = {}

    def score_source(
        self,
        url: str,
        title: str = "",
        content: str = "",
        detected_date: str | None = None,
    ) -> SourceInfo:
        """
        –û—Ü–µ–Ω–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –ø–æ URL –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É.

        Returns:
            SourceInfo —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–º–∏ –æ—Ü–µ–Ω–∫–∞–º–∏
        """
        parsed = urlparse(url)
        domain = parsed.netloc.lower().removeprefix("www.")
        tld = domain.split(".")[-1] if "." in domain else ""

        # 1. –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ –¥–æ–º–µ–Ω—É
        trust = self._get_domain_trust(domain, tld)

        # 2. HTTPS –±–æ–Ω—É—Å
        if parsed.scheme == "https":
            trust = min(1.0, trust + 0.05)

        # 3. –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content_len = len(content)
        if content_len < 100:
            trust *= 0.7   # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
        elif content_len > 2000:
            trust = min(1.0, trust + 0.05)  # –ü–æ–¥—Ä–æ–±–Ω—ã–π

        # 4. –°–≤–µ–∂–µ—Å—Ç—å
        freshness = self._estimate_freshness(content, detected_date)

        # 5. –û–ø—Ä–µ–¥–µ–ª—è–µ–º reliability
        if trust >= 0.75:
            reliability = SourceReliability.HIGH
        elif trust >= 0.45:
            reliability = SourceReliability.MEDIUM
        else:
            reliability = SourceReliability.LOW

        return SourceInfo(
            url=url,
            domain=domain,
            title=title,
            trust_score=round(trust, 3),
            reliability=reliability,
            freshness_score=round(freshness, 3),
            content_length=content_len,
            detected_date=detected_date,
        )

    def _get_domain_trust(self, domain: str, tld: str) -> float:
        """–ü–æ–ª—É—á–∏—Ç—å trust score –¥–ª—è –¥–æ–º–µ–Ω–∞."""
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if domain in self._custom_scores:
            return self._custom_scores[domain]
        if domain in self._domain_scores:
            return self._domain_scores[domain]

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ parent domain
        parts = domain.split(".")
        for i in range(1, len(parts)):
            parent = ".".join(parts[i:])
            if parent in self._domain_scores:
                return self._domain_scores[parent]

        # TLD-–±–∞–∑–æ–≤–æ–µ
        if tld in self._domain_scores:
            return self._domain_scores[tld]

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ untrusted
        for pattern in UNTRUSTED_PATTERNS:
            if pattern in domain:
                return 0.3

        # Default
        return 0.5

    def _estimate_freshness(
        self,
        content: str,
        detected_date: str | None = None,
    ) -> float:
        """–û—Ü–µ–Ω–∏—Ç—å —Å–≤–µ–∂–µ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞."""
        if detected_date:
            try:
                # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É
                for fmt in ("%Y-%m-%d", "%Y/%m/%d", "%d.%m.%Y", "%B %d, %Y"):
                    try:
                        dt = datetime.strptime(detected_date, fmt)
                        days_old = (datetime.now() - dt).days
                        if days_old < 30:
                            return 1.0
                        elif days_old < 180:
                            return 0.8
                        elif days_old < 365:
                            return 0.6
                        elif days_old < 730:
                            return 0.4
                        else:
                            return 0.2
                    except ValueError:
                        continue
            except Exception:
                pass

        # –ò—â–µ–º –¥–∞—Ç—ã –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ
        if content:
            for pattern in FRESHNESS_PATTERNS:
                match = pattern.search(content[:2000])
                if match:
                    # –ù–∞—à–ª–∏ –¥–∞—Ç—É ‚Üí —Å—Ä–µ–¥–Ω–µ-—Å–≤–µ–∂–∏–π
                    return 0.6

        # –ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        return 0.5

    def add_custom_domain(self, domain: str, score: float) -> None:
        """–î–æ–±–∞–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é –æ—Ü–µ–Ω–∫—É –¥–æ–º–µ–Ω–∞."""
        self._custom_scores[domain] = max(0.0, min(1.0, score))

    def get_domain_score(self, domain: str) -> float | None:
        """–ü–æ–ª—É—á–∏—Ç—å score –¥–ª—è –¥–æ–º–µ–Ω–∞."""
        domain = domain.lower().removeprefix("www.")
        if domain in self._custom_scores:
            return self._custom_scores[domain]
        if domain in self._domain_scores:
            return self._domain_scores[domain]
        return None


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 2. QUERY EXPANDER ‚Äî –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


class QueryExpander:
    """
    –†–∞—Å—à–∏—Ä—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è.

    –°—Ç—Ä–∞—Ç–µ–≥–∏–∏:
    - –°–∏–Ω–æ–Ω–∏–º—ã –∏ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏
    - –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (—Ü–µ–Ω—ã, –æ—Ç–∑—ã–≤—ã, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ)
    - –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–≥–æ–¥, —Ä–µ–≥–∏–æ–Ω)
    """

    # –®–∞–±–ª–æ–Ω—ã —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –ø–æ —Ç–∏–ø—É –∑–∞–ø—Ä–æ—Å–∞
    EXPANSION_TEMPLATES: dict[str, list[str]] = {
        "price": [
            "{query} —Ü–µ–Ω–∞",
            "{query} —Å—Ç–æ–∏–º–æ—Å—Ç—å –∫—É–ø–∏—Ç—å",
            "{query} price comparison",
        ],
        "review": [
            "{query} –æ—Ç–∑—ã–≤—ã",
            "{query} review",
            "{query} –ø–ª—é—Å—ã –º–∏–Ω—É—Å—ã",
        ],
        "howto": [
            "{query} –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è",
            "{query} how to guide",
            "{query} –ø–æ—à–∞–≥–æ–≤–æ",
        ],
        "comparison": [
            "{query} —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ",
            "{query} vs –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã",
            "{query} –ª—É—á—à–∏–π –≤—ã–±–æ—Ä",
        ],
        "news": [
            "{query} –Ω–æ–≤–æ—Å—Ç–∏ 2025 2026",
            "{query} –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è",
            "{query} latest news",
        ],
        "definition": [
            "—á—Ç–æ —Ç–∞–∫–æ–µ {query}",
            "{query} –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ",
            "{query} wiki",
        ],
    }

    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞
    TYPE_KEYWORDS: dict[str, list[str]] = {
        "price": ["—Ü–µ–Ω–∞", "—Å—Ç–æ–∏–º–æ—Å—Ç—å", "–∫—É–ø–∏—Ç—å", "price", "cost", "—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç"],
        "review": ["–æ—Ç–∑—ã–≤", "review", "–º–Ω–µ–Ω–∏–µ", "–æ—Ü–µ–Ω–∫", "—Ä–µ–π—Ç–∏–Ω–≥"],
        "howto": ["–∫–∞–∫ ", "how to", "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", "–Ω–∞—Å—Ç—Ä–æ–∏", "—É—Å—Ç–∞–Ω–æ–≤–∏", "—Å–¥–µ–ª–∞—Ç—å"],
        "comparison": ["—Å—Ä–∞–≤–Ω", "–ª—É—á—à", "vs", "–∏–ª–∏", "versus", "compare"],
        "news": ["–Ω–æ–≤–æ—Å—Ç", "news", "–æ–±–Ω–æ–≤–ª–µ–Ω", "latest", "–ø–æ—Å–ª–µ–¥–Ω"],
        "definition": ["—á—Ç–æ —Ç–∞–∫–æ–µ", "what is", "–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", "define"],
    }

    def expand(
        self,
        query: str,
        max_queries: int = 3,
        force_type: str | None = None,
    ) -> list[str]:
        """
        –†–∞—Å—à–∏—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å.

        Args:
            query: –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            max_queries: –ú–∞–∫—Å–∏–º—É–º –∑–∞–ø—Ä–æ—Å–æ–≤ (–≤–∫–ª—é—á–∞—è –æ—Ä–∏–≥–∏–Ω–∞–ª)
            force_type: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Ç–∏–ø (price, review, howto, ...)

        Returns:
            –°–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ (–æ—Ä–∏–≥–∏–Ω–∞–ª + —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)
        """
        queries = [query]

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
        query_type = force_type or self._detect_type(query)

        # –ü–æ–ª—É—á–∞–µ–º —à–∞–±–ª–æ–Ω—ã —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
        templates = self.EXPANSION_TEMPLATES.get(query_type, [])

        for template in templates:
            if len(queries) >= max_queries:
                break
            expanded = template.format(query=query)
            if expanded not in queries:
                queries.append(expanded)

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–±—Ä–∞–ª–∏ ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –≥–æ–¥
        if len(queries) < max_queries:
            year_query = f"{query} 2026"
            if year_query not in queries:
                queries.append(year_query)

        return queries[:max_queries]

    def _detect_type(self, query: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º."""
        query_lower = query.lower()

        for qtype, keywords in self.TYPE_KEYWORDS.items():
            for kw in keywords:
                if kw in query_lower:
                    return qtype

        return "general"

    def detect_query_type(self, query: str) -> str:
        """–ü—É–±–ª–∏—á–Ω—ã–π –º–µ—Ç–æ–¥ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞."""
        return self._detect_type(query)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 3. FACT EXTRACTOR ‚Äî –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


class FactExtractor:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã.

    –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ñ–∞–∫—Ç–æ–≤:
    - general: –æ–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    - price: —Ü–µ–Ω—ã –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
    - date: –¥–∞—Ç—ã –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏
    - statistic: —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    - opinion: –º–Ω–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏
    """

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ–≤
    PRICE_PATTERN = re.compile(
        r"[\$‚Ç¨¬£¬•‚ÇΩ‚Ç∏]\s*[\d,.]+|[\d,.]+\s*(?:USD|EUR|RUB|TMT|CNY|—Ä—É–±|–¥–æ–ª–ª|"
        r"–º–∞–Ω–∞—Ç|—é–∞–Ω|—Ç–µ–Ω–≥–µ)",
        re.I,
    )

    STATISTIC_PATTERN = re.compile(
        r"\d+[.,]?\d*\s*(?:%|–ø—Ä–æ—Ü–µ–Ω—Ç|percent|–º–ª–Ω|–º–ª—Ä–¥|—Ç—ã—Å|billion|million|"
        r"thousand|GB|MB|TB|–∫–≥|kg|–∫–º|km|–º¬≤|–≥–∞)",
        re.I,
    )

    DATE_PATTERN = re.compile(
        r"\d{4}[-/]\d{1,2}[-/]\d{1,2}|"
        r"\d{1,2}\s+(?:—è–Ω–≤|—Ñ–µ–≤|–º–∞—Ä|–∞–ø—Ä|–º–∞—è|–∏—é–Ω|–∏—é–ª|–∞–≤–≥|—Å–µ–Ω|–æ–∫—Ç|–Ω–æ—è|–¥–µ–∫)"
        r"[–∞-—è—ë]*\s+\d{4}",
        re.I,
    )

    OPINION_MARKERS = [
        "—Å—á–∏—Ç–∞—é", "–¥—É–º–∞—é", "–ø–æ–ª–∞–≥–∞—é", "–ø–æ –º–æ–µ–º—É",
        "i think", "i believe", "in my opinion",
        "—Ä–µ–∫–æ–º–µ–Ω–¥—É—é", "—Å–æ–≤–µ—Ç—É—é", "recommend",
        "–ª—É—á—à–∏–π", "—Ö—É–¥—à–∏–π", "best", "worst",
    ]

    def extract_facts(
        self,
        text: str,
        source: SourceInfo,
        query: str = "",
        max_facts: int = 10,
    ) -> list[ExtractedFact]:
        """
        –ò–∑–≤–ª–µ—á—å —Ñ–∞–∫—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞.

        Args:
            text: –¢–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            source: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ
            query: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å (–¥–ª—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏)
            max_facts: –ú–∞–∫—Å–∏–º—É–º —Ñ–∞–∫—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ ExtractedFact
        """
        if not text or not text.strip():
            return []

        facts: list[ExtractedFact] = []

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = self._split_sentences(text)

        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫ –∑–∞–ø—Ä–æ—Å—É
        if query:
            sentences = self._filter_relevant(sentences, query)

        for sentence in sentences[:max_facts * 3]:
            if len(facts) >= max_facts:
                break

            sentence = sentence.strip()
            if len(sentence) < 15 or len(sentence) > 500:
                continue

            category = self._categorize(sentence)
            keywords = self._extract_keywords(sentence, query)
            confidence = self._estimate_confidence(
                sentence, source, category
            )

            facts.append(ExtractedFact(
                text=sentence,
                source=source,
                confidence=confidence,
                category=category,
                keywords=keywords,
            ))

        return facts

    def _split_sentences(self, text: str) -> list[str]:
        """–†–∞–∑–±–∏—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        # –ü—Ä–æ—Å—Ç–æ–π —Å–ø–ª–∏—Ç—Ç–µ—Ä –ø–æ —Ç–æ—á–∫–∞–º, ! –∏ ?
        sentences = re.split(r'(?<=[.!?])\s+', text)
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—É—Å—Ç—ã—Ö –∏ –∫–æ—Ä–æ—Ç–∫–∏—Ö
        return [s.strip() for s in sentences if len(s.strip()) > 10]

    def _filter_relevant(
        self,
        sentences: list[str],
        query: str,
    ) -> list[str]:
        """–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        query_words = set(query.lower().split())
        scored = []

        for s in sentences:
            s_lower = s.lower()
            # –°—á–∏—Ç–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å–ª–æ–≤ –∑–∞–ø—Ä–æ—Å–∞
            overlap = sum(1 for w in query_words if w in s_lower)
            if overlap > 0:
                scored.append((overlap, s))

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        scored.sort(key=lambda x: x[0], reverse=True)

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ + –æ—Å—Ç–∞–ª—å–Ω—ã–µ (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ –º–∞–ª–æ)
        relevant = [s for _, s in scored]
        other = [s for s in sentences if s not in relevant]
        return relevant + other

    def _categorize(self, sentence: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ñ–∞–∫—Ç–∞."""
        if self.PRICE_PATTERN.search(sentence):
            return "price"
        if self.STATISTIC_PATTERN.search(sentence):
            return "statistic"
        if self.DATE_PATTERN.search(sentence):
            return "date"

        s_lower = sentence.lower()
        for marker in self.OPINION_MARKERS:
            if marker in s_lower:
                return "opinion"

        return "general"

    def _extract_keywords(
        self,
        sentence: str,
        query: str = "",
    ) -> list[str]:
        """–ò–∑–≤–ª–µ—á—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞."""
        # –°–ª–æ–≤–∞ –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–µ—Å—è —Å –∑–∞–ø—Ä–æ—Å–æ–º
        words = re.findall(r'\b[–∞-—è—ëa-z]{3,}\b', sentence.lower())
        query_words = set(re.findall(r'\b[–∞-—è—ëa-z]{3,}\b', query.lower()))

        keywords = []
        for w in words:
            if w in query_words and w not in keywords:
                keywords.append(w)

        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–∏–º—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        stopwords = {
            "—ç—Ç–æ", "—á—Ç–æ", "–∫–∞–∫", "–¥–ª—è", "–ø—Ä–∏", "–∏–ª–∏", "the",
            "and", "for", "with", "from", "that", "this",
            "can", "are", "was", "has", "have", "been",
            "–µ–≥–æ", "–æ–Ω–∞", "–æ–Ω–∏", "–Ω–∞—Å", "–≤–∞—Å", "–≤—Å–µ",
        }
        for w in words:
            if w not in stopwords and w not in keywords and len(w) > 3:
                keywords.append(w)
                if len(keywords) >= 5:
                    break

        return keywords

    def _estimate_confidence(
        self,
        sentence: str,
        source: SourceInfo,
        category: str,
    ) -> float:
        """–û—Ü–µ–Ω–∏—Ç—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ñ–∞–∫—Ç–µ."""
        base = source.trust_score

        # –§–∞–∫—Ç—ã —Å —Ü–∏—Ñ—Ä–∞–º–∏ –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã
        if category in ("price", "statistic", "date"):
            base = min(1.0, base + 0.1)

        # –ú–Ω–µ–Ω–∏—è –º–µ–Ω–µ–µ –Ω–∞–¥—ë–∂–Ω—ã
        if category == "opinion":
            base *= 0.8

        # –ö–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–µ–Ω–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã
        if len(sentence) < 30:
            base *= 0.9

        return round(base, 3)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 4. CONTRADICTION DETECTOR ‚Äî –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


class ContradictionDetector:
    """
    –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –º–µ–∂–¥—É —Ñ–∞–∫—Ç–∞–º–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.

    –ú–µ—Ç–æ–¥—ã –¥–µ—Ç–µ–∫—Ü–∏–∏:
    - –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è (—Ä–∞–∑–Ω—ã–µ —Ü–µ–Ω—ã, –¥–∞—Ç—ã, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
    - –¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è (–∞–Ω—Ç–æ–Ω–∏–º—ã, –æ—Ç—Ä–∏—Ü–∞–Ω–∏—è)
    - –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ + —Ä–∞–∑–ª–∏—á–∏–µ –≤ —Ñ–∞–∫—Ç–∞—Ö
    """

    # –ü–∞—Ä—ã –∞–Ω—Ç–æ–Ω–∏–º–æ–≤/–æ—Ç—Ä–∏—Ü–∞–Ω–∏–π
    CONTRADICTION_PAIRS: list[tuple[str, str]] = [
        ("–¥–∞", "–Ω–µ—Ç"),
        ("yes", "no"),
        ("–ø—Ä–∞–≤–¥–∞", "–ª–æ–∂—å"),
        ("true", "false"),
        ("—Ä–æ—Å—Ç", "–ø–∞–¥–µ–Ω–∏–µ"),
        ("increase", "decrease"),
        ("growth", "decline"),
        ("–ª—É—á—à–µ", "—Ö—É–∂–µ"),
        ("better", "worse"),
        ("–±–æ–ª—å—à–µ", "–º–µ–Ω—å—à–µ"),
        ("more", "less"),
        ("–¥–æ—Ä–æ–≥–æ–π", "–¥–µ—à—ë–≤—ã–π"),
        ("expensive", "cheap"),
        ("–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç", "–Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç"),
        ("supports", "doesn't support"),
        ("–±–µ—Å–ø–ª–∞—Ç–Ω–æ", "–ø–ª–∞—Ç–Ω–æ"),
        ("free", "paid"),
        ("–¥–æ—Å—Ç—É–ø–µ–Ω", "–Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"),
        ("available", "unavailable"),
    ]

    NEGATION_WORDS = [
        "–Ω–µ", "–Ω–µ—Ç", "–±–µ–∑", "–Ω–∏–∫–æ–≥–¥–∞", "–Ω–∏—á–µ–≥–æ",
        "not", "no", "never", "none", "neither", "nor",
        "don't", "doesn't", "isn't", "aren't", "won't",
    ]

    def detect(
        self,
        facts: list[ExtractedFact],
        similarity_threshold: float = 0.3,
    ) -> list[Contradiction]:
        """
        –û–±–Ω–∞—Ä—É–∂–∏—Ç—å –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –º–µ–∂–¥—É —Ñ–∞–∫—Ç–∞–º–∏.

        Args:
            facts: –°–ø–∏—Å–æ–∫ —Ñ–∞–∫—Ç–æ–≤
            similarity_threshold: –ü–æ—Ä–æ–≥ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π
        """
        contradictions: list[Contradiction] = []

        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—É—é –ø–∞—Ä—É —Ñ–∞–∫—Ç–æ–≤
        for i in range(len(facts)):
            for j in range(i + 1, len(facts)):
                fa, fb = facts[i], facts[j]

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–∫—Ç—ã –∏–∑ –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                if fa.source.url == fb.source.url:
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
                similarity = self._topic_similarity(fa, fb)
                if similarity < similarity_threshold:
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è
                num_contradiction = self._check_numeric(fa, fb)
                if num_contradiction:
                    contradictions.append(num_contradiction)
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è
                text_contradiction = self._check_textual(fa, fb)
                if text_contradiction:
                    contradictions.append(text_contradiction)

        return contradictions

    def _topic_similarity(self, fa: ExtractedFact, fb: ExtractedFact) -> float:
        """–¢–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É —Ñ–∞–∫—Ç–∞–º–∏ (–ø–æ keywords)."""
        if not fa.keywords or not fb.keywords:
            return 0.0

        set_a = set(fa.keywords)
        set_b = set(fb.keywords)

        intersection = len(set_a & set_b)
        union = len(set_a | set_b)

        if union == 0:
            return 0.0

        return intersection / union

    def _check_numeric(
        self,
        fa: ExtractedFact,
        fb: ExtractedFact,
    ) -> Contradiction | None:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è."""
        if fa.category not in ("price", "statistic") or \
           fb.category not in ("price", "statistic"):
            return None

        nums_a = re.findall(r'[\d,.]+', fa.text)
        nums_b = re.findall(r'[\d,.]+', fb.text)

        if not nums_a or not nums_b:
            return None

        # –ü–∞—Ä—Å–∏–º —á–∏—Å–ª–∞
        try:
            val_a = float(nums_a[0].replace(",", ""))
            val_b = float(nums_b[0].replace(",", ""))
        except (ValueError, IndexError):
            return None

        if val_a == 0 or val_b == 0:
            return None

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ > 30%
        diff_ratio = abs(val_a - val_b) / max(val_a, val_b)

        if diff_ratio > 0.3:
            severity = (
                ContradictionSeverity.MAJOR if diff_ratio > 0.5
                else ContradictionSeverity.MODERATE
            )
            return Contradiction(
                fact_a=fa,
                fact_b=fb,
                severity=severity,
                description=(
                    f"–ß–∏—Å–ª–æ–≤–æ–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ: {val_a} vs {val_b} "
                    f"(—Ä–∞–∑–Ω–∏—Ü–∞ {diff_ratio:.0%})"
                ),
            )

        return None

    def _check_textual(
        self,
        fa: ExtractedFact,
        fb: ExtractedFact,
    ) -> Contradiction | None:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è."""
        text_a = fa.text.lower()
        text_b = fb.text.lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω—Ç–æ–Ω–∏–º—ã
        for word_a, word_b in self.CONTRADICTION_PAIRS:
            if word_a in text_a and word_b in text_b:
                return Contradiction(
                    fact_a=fa,
                    fact_b=fb,
                    severity=ContradictionSeverity.MODERATE,
                    description=f"–ü—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è: '{word_a}' vs '{word_b}'",
                )
            if word_b in text_a and word_a in text_b:
                return Contradiction(
                    fact_a=fa,
                    fact_b=fb,
                    severity=ContradictionSeverity.MODERATE,
                    description=f"–ü—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è: '{word_b}' vs '{word_a}'",
                )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç—Ä–∏—Ü–∞–Ω–∏—è
        negation_a = any(neg in text_a for neg in self.NEGATION_WORDS)
        negation_b = any(neg in text_b for neg in self.NEGATION_WORDS)

        if negation_a != negation_b:
            # –û–¥–Ω–æ —É—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç, –¥—Ä—É–≥–æ–µ –æ—Ç—Ä–∏—Ü–∞–µ—Ç
            overlap = set(fa.keywords) & set(fb.keywords)
            if len(overlap) >= 2:
                return Contradiction(
                    fact_a=fa,
                    fact_b=fb,
                    severity=ContradictionSeverity.MINOR,
                    description="–û–¥–Ω–æ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Ç—Ä–∏—Ü–∞–Ω–∏–µ",
                )

        return None


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 5. FACT SYNTHESIZER ‚Äî –°–∏–Ω—Ç–µ–∑ –æ—Ç–≤–µ—Ç–∞
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


class FactSynthesizer:
    """
    –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç –∏–∑ —Ñ–∞–∫—Ç–æ–≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.

    –°—Ç—Ä–∞—Ç–µ–≥–∏–∏:
    - Weighted voting: —Ñ–∞–∫—Ç—ã –≤–∑–≤–µ—à–∏–≤–∞—é—Ç—Å—è –ø–æ trust * confidence
    - Deduplication: —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    - Citation: —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    """

    def synthesize(
        self,
        query: str,
        facts: list[ExtractedFact],
        sources: list[SourceInfo],
        contradictions: list[Contradiction],
    ) -> SynthesizedAnswer:
        """
        –°–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –∏–∑ —Ñ–∞–∫—Ç–æ–≤.

        Args:
            query: –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            facts: –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã
            sources: –ò—Å—Ç–æ—á–Ω–∏–∫–∏
            contradictions: –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è

        Returns:
            SynthesizedAnswer
        """
        if not facts:
            return SynthesizedAnswer(
                query=query,
                summary=f"–ü–æ –∑–∞–ø—Ä–æ—Å—É ¬´{query}¬ª –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.",
                facts=[],
                sources=sources,
                contradictions=contradictions,
                confidence=0.0,
                sources_count=len(sources),
            )

        # 1. –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Ñ–∞–∫—Ç–æ–≤
        unique_facts = self._deduplicate(facts)

        # 2. –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ weighted score
        scored = [
            (f, f.confidence * f.source.composite_score)
            for f in unique_facts
        ]
        scored.sort(key=lambda x: x[1], reverse=True)

        # 3. –°—á–∏—Ç–∞–µ–º –æ–±—â—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        confidence = self._compute_confidence(
            scored, contradictions, len(sources)
        )

        # 4. –°–æ–±–∏—Ä–∞–µ–º summary
        summary = self._build_summary(query, scored, contradictions)

        return SynthesizedAnswer(
            query=query,
            summary=summary,
            facts=[f for f, _ in scored],
            sources=sources,
            contradictions=contradictions,
            confidence=round(confidence, 3),
            sources_count=len(sources),
        )

    def _deduplicate(
        self,
        facts: list[ExtractedFact],
        threshold: float = 0.7,
    ) -> list[ExtractedFact]:
        """–£–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã (–ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤—É)."""
        unique: list[ExtractedFact] = []

        for fact in facts:
            is_dup = False
            for existing in unique:
                if self._text_similarity(fact.text, existing.text) > threshold:
                    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ñ–∞–∫—Ç —Å –±–æ–ª—å—à–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                    if fact.confidence > existing.confidence:
                        unique.remove(existing)
                        unique.append(fact)
                    is_dup = True
                    break
            if not is_dup:
                unique.append(fact)

        return unique

    def _text_similarity(self, a: str, b: str) -> float:
        """Jaccard similarity –ø–æ —Å–ª–æ–≤–∞–º."""
        words_a = set(a.lower().split())
        words_b = set(b.lower().split())

        if not words_a or not words_b:
            return 0.0

        intersection = len(words_a & words_b)
        union = len(words_a | words_b)

        return intersection / union if union > 0 else 0.0

    def _compute_confidence(
        self,
        scored_facts: list[tuple[ExtractedFact, float]],
        contradictions: list[Contradiction],
        sources_count: int,
    ) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –æ–±—â—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å."""
        if not scored_facts:
            return 0.0

        # –°—Ä–µ–¥–Ω–µ–µ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        total_score = sum(s for _, s in scored_facts)
        avg = total_score / len(scored_facts)

        # –ë–æ–Ω—É—Å –∑–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        source_bonus = min(0.15, sources_count * 0.03)

        # –®—Ç—Ä–∞—Ñ –∑–∞ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è
        contradiction_penalty = len(contradictions) * 0.1
        major_penalty = sum(
            0.15 for c in contradictions
            if c.severity == ContradictionSeverity.MAJOR
        )

        confidence = avg + source_bonus - contradiction_penalty - major_penalty
        return max(0.0, min(1.0, confidence))

    def _build_summary(
        self,
        query: str,
        scored_facts: list[tuple[ExtractedFact, float]],
        contradictions: list[Contradiction],
    ) -> str:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤–æ–µ summary."""
        lines = [f"üìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: ¬´{query}¬ª\n"]

        # –¢–æ–ø —Ñ–∞–∫—Ç—ã
        top_facts = scored_facts[:5]
        if top_facts:
            lines.append("üìå –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã:")
            for i, (fact, score) in enumerate(top_facts, 1):
                domain = fact.source.domain
                lines.append(
                    f"  {i}. {fact.text[:200]} "
                    f"[{domain}, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {score:.0%}]"
                )

        # –ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è
        if contradictions:
            lines.append(f"\n‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π: {len(contradictions)}")
            for c in contradictions[:3]:
                lines.append(f"  ‚Ä¢ {c.description}")

        return "\n".join(lines)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 6. INTERNET REASONING ENGINE ‚Äî –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


class InternetReasoningEngine:
    """
    –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å Internet Reasoning Layer.

    –û—Ä–∫–µ—Å—Ç—Ä–∏—Ä—É–µ—Ç –≤–µ—Å—å pipeline:
    Query ‚Üí Expand ‚Üí Search ‚Üí Extract ‚Üí Score ‚Üí Detect ‚Üí Synthesize

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Browser Engine –¥–ª—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É.
    """

    def __init__(self):
        self._trust_scorer = TrustScorer()
        self._query_expander = QueryExpander()
        self._fact_extractor = FactExtractor()
        self._contradiction_detector = ContradictionDetector()
        self._fact_synthesizer = FactSynthesizer()
        self._stats = ResearchStats()

    @property
    def trust_scorer(self) -> TrustScorer:
        return self._trust_scorer

    @property
    def query_expander(self) -> QueryExpander:
        return self._query_expander

    @property
    def fact_extractor(self) -> FactExtractor:
        return self._fact_extractor

    @property
    def contradiction_detector(self) -> ContradictionDetector:
        return self._contradiction_detector

    @property
    def fact_synthesizer(self) -> FactSynthesizer:
        return self._fact_synthesizer

    @property
    def stats(self) -> ResearchStats:
        return self._stats

    async def research(
        self,
        query: str,
        max_sources: int = 5,
        expand_queries: bool = True,
        max_facts_per_source: int = 5,
    ) -> SynthesizedAnswer:
        """
        –ü–æ–ª–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞.

        1. –†–∞—Å—à–∏—Ä—è–µ—Ç –∑–∞–ø—Ä–æ—Å
        2. –ò—â–µ—Ç –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
        3. –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü
        4. –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        5. –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∞–∫—Ç—ã
        6. –ò—â–µ—Ç –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è
        7. –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç

        Args:
            query: –í–æ–ø—Ä–æ—Å –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            max_sources: –ú–∞–∫—Å–∏–º—É–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            expand_queries: –†–∞—Å—à–∏—Ä—è—Ç—å –ª–∏ –∑–∞–ø—Ä–æ—Å—ã
            max_facts_per_source: –ú–∞–∫—Å–∏–º—É–º —Ñ–∞–∫—Ç–æ–≤ —Å –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞

        Returns:
            SynthesizedAnswer
        """
        import time
        start = time.monotonic()

        from pds_ultimate.core.browser_engine import browser_engine

        # 1. –†–∞—Å—à–∏—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å—ã
        if expand_queries:
            queries = self._query_expander.expand(query, max_queries=3)
        else:
            queries = [query]

        # 2. –ò—â–µ–º
        all_search_results = []
        seen_urls: set[str] = set()

        for q in queries:
            try:
                results = await browser_engine.web_search(
                    q, max_results=max_sources
                )
                for r in results:
                    if r.url not in seen_urls:
                        all_search_results.append(r)
                        seen_urls.add(r.url)
                self._stats.queries_performed += 1
            except Exception as e:
                logger.warning(f"Search error for '{q}': {e}")

        # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü
        sources: list[SourceInfo] = []
        all_facts: list[ExtractedFact] = []

        for result in all_search_results[:max_sources]:
            try:
                extracted = await browser_engine.extract_data(result.url)
                self._stats.pages_analyzed += 1

                # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫
                source_info = self._trust_scorer.score_source(
                    url=result.url,
                    title=extracted.title or result.title,
                    content=extracted.text,
                )
                sources.append(source_info)

                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∞–∫—Ç—ã
                facts = self._fact_extractor.extract_facts(
                    text=extracted.text,
                    source=source_info,
                    query=query,
                    max_facts=max_facts_per_source,
                )
                all_facts.extend(facts)
                self._stats.facts_extracted += len(facts)

            except Exception as e:
                logger.warning(f"Extract error for {result.url}: {e}")

        # 4. –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ–º –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è
        contradictions = self._contradiction_detector.detect(all_facts)
        self._stats.contradictions_found += len(contradictions)

        # 5. –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        answer = self._fact_synthesizer.synthesize(
            query=query,
            facts=all_facts,
            sources=sources,
            contradictions=contradictions,
        )

        elapsed = int((time.monotonic() - start) * 1000)
        self._stats.total_time_ms += elapsed

        logger.info(
            f"Research '{query[:50]}': "
            f"{len(sources)} sources, {len(all_facts)} facts, "
            f"{len(contradictions)} contradictions, {elapsed}ms"
        )

        return answer

    async def quick_search(
        self,
        query: str,
        max_results: int = 5,
    ) -> SynthesizedAnswer:
        """
        –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤.
        –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.
        """
        return await self.research(
            query=query,
            max_sources=max_results,
            expand_queries=False,
            max_facts_per_source=3,
        )

    async def deep_research(
        self,
        query: str,
        max_sources: int = 10,
    ) -> SynthesizedAnswer:
        """
        –ì–ª—É–±–æ–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º –∏ –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
        –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.
        """
        return await self.research(
            query=query,
            max_sources=max_sources,
            expand_queries=True,
            max_facts_per_source=8,
        )

    def get_stats(self) -> dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π."""
        return self._stats.to_dict()

    def reset_stats(self) -> None:
        """–°–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏."""
        self._stats = ResearchStats()


# ‚îÄ‚îÄ‚îÄ –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

reasoning_engine = InternetReasoningEngine()
