"""
PDS-Ultimate Memory v2 (Part 8)
==================================
ĞŸĞ°Ğ¼ÑÑ‚ÑŒ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾ĞºĞ¾Ğ»ĞµĞ½Ğ¸Ñ â€” ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ°Ñ, Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ, Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ°ÑÑÑ.

Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ memory.py Ğ¸ advanced_memory_manager.py:

1. Strategic Memory â€” Ğ°Ğ³ĞµĞ½Ñ‚ ÑƒÑ‡Ğ¸Ñ‚ÑÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ¸, Ğ²Ñ‹Ğ´ĞµĞ»ÑÑ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹
2. Failure-Driven Learning v2 â€” Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ñ… Ñ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸ĞµĞ¹
3. Embedding-ready Memory â€” Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ´Ğ»Ñ vector search
4. Memory Consolidation â€” Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸Ñ… Ğ²Ğ¾ÑĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ğ¹
5. Adaptive Recall â€” Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ñ‚ Ğ¾Ñ‚ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¸ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸
6. Memory Pruning v2 â€” ÑƒĞ¼Ğ½Ğ¾Ğµ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ñ ÑƒÑ‡Ñ‘Ñ‚Ğ¾Ğ¼ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸
7. Cross-session Learning â€” Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞµÑÑĞ¸ÑĞ¼Ğ¸
8. Emotional Memory Tags â€” Ğ²Ğ¾ÑĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ñ Ñ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾ĞºÑ€Ğ°ÑĞºĞ¾Ğ¹
9. Skill Library â€” ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ¿ĞµÑ€ĞµĞ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑƒÑĞ¿ĞµÑˆĞ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹
10. Context Window Optimizer â€” Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° LLM
"""

from __future__ import annotations

import re
from collections import Counter, defaultdict
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any

from pds_ultimate.config import logger

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SKILL LIBRARY â€” Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ ÑƒÑĞ¿ĞµÑˆĞ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@dataclass
class Skill:
    """
    ĞĞ°Ğ²Ñ‹Ğº/ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€ÑƒÑ Ğ°Ğ³ĞµĞ½Ñ‚ Ğ²Ñ‹ÑƒÑ‡Ğ¸Ğ».

    ĞŸÑ€Ğ¸Ğ¼ĞµÑ€:
    - ĞĞ°Ğ²Ñ‹Ğº: "ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ²Ğ°Ğ»ÑÑ‚ TMT â†’ USD"
    - ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½: "ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚|ĞºÑƒÑ€Ñ|TMT|Ğ¼Ğ°Ğ½Ğ°Ñ‚"
    - Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ: "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ exchange_rates Ñ from=TMT, to=USD"
    - Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚ÑŒ: 95% (19/20 ÑƒÑĞ¿ĞµÑˆĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
    """
    id: str = ""
    name: str = ""
    description: str = ""
    pattern: str = ""              # Regex Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½ Ğ´Ğ»Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¸
    strategy: str = ""             # ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸
    tools_used: list[str] = field(default_factory=list)
    success_count: int = 0
    failure_count: int = 0
    last_used: datetime = field(default_factory=datetime.utcnow)
    created_at: datetime = field(default_factory=datetime.utcnow)
    tags: list[str] = field(default_factory=list)

    @property
    def success_rate(self) -> float:
        total = self.success_count + self.failure_count
        if total == 0:
            return 0.0
        return self.success_count / total

    @property
    def total_uses(self) -> int:
        return self.success_count + self.failure_count

    def matches(self, text: str) -> bool:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ, Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ»Ğ¸ Ğ½Ğ°Ğ²Ñ‹Ğº Ğ´Ğ»Ñ Ñ‚ĞµĞºÑÑ‚Ğ°."""
        if not self.pattern:
            return False
        try:
            return bool(re.search(self.pattern, text.lower()))
        except re.error:
            return False

    def to_dict(self) -> dict:
        return {
            "id": self.id,
            "name": self.name,
            "strategy": self.strategy,
            "success_rate": f"{self.success_rate:.0%}",
            "total_uses": self.total_uses,
            "tools": self.tools_used,
            "tags": self.tags,
        }


class SkillLibrary:
    """Ğ‘Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ° Ğ½Ğ°Ğ²Ñ‹ĞºĞ¾Ğ² Ğ°Ğ³ĞµĞ½Ñ‚Ğ°."""

    def __init__(self):
        self._skills: dict[str, Skill] = {}
        self._skill_counter: int = 0

    def add_skill(
        self,
        name: str,
        description: str = "",
        pattern: str = "",
        strategy: str = "",
        tools_used: list[str] | None = None,
        tags: list[str] | None = None,
    ) -> Skill:
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ½Ğ°Ğ²Ñ‹Ğº."""
        self._skill_counter += 1
        skill_id = f"skill_{self._skill_counter}"

        skill = Skill(
            id=skill_id,
            name=name,
            description=description,
            pattern=pattern,
            strategy=strategy,
            tools_used=tools_used or [],
            tags=tags or [],
        )

        self._skills[skill_id] = skill
        logger.debug(f"Skill added: {name} (pattern={pattern})")
        return skill

    def find_matching(self, text: str, min_success_rate: float = 0.5) -> list[Skill]:
        """ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ Ğ½Ğ°Ğ²Ñ‹ĞºĞ¸ Ğ´Ğ»Ñ Ñ‚ĞµĞºÑÑ‚Ğ°."""
        matches = []
        for skill in self._skills.values():
            if skill.matches(text) and skill.success_rate >= min_success_rate:
                matches.append(skill)

        # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚Ğ¸
        return sorted(matches, key=lambda s: s.success_rate, reverse=True)

    def record_usage(self, skill_id: str, success: bool) -> None:
        """Ğ—Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ°Ğ²Ñ‹ĞºĞ°."""
        skill = self._skills.get(skill_id)
        if not skill:
            return

        if success:
            skill.success_count += 1
        else:
            skill.failure_count += 1
        skill.last_used = datetime.utcnow()

    def get_skill(self, skill_id: str) -> Skill | None:
        return self._skills.get(skill_id)

    def remove_skill(self, skill_id: str) -> bool:
        return self._skills.pop(skill_id, None) is not None

    @property
    def count(self) -> int:
        return len(self._skills)

    def get_top_skills(self, limit: int = 10) -> list[Skill]:
        """Ğ¡Ğ°Ğ¼Ñ‹Ğµ ÑƒÑĞ¿ĞµÑˆĞ½Ñ‹Ğµ Ğ½Ğ°Ğ²Ñ‹ĞºĞ¸."""
        skills = list(self._skills.values())
        return sorted(
            skills,
            key=lambda s: (s.success_rate, s.total_uses),
            reverse=True,
        )[:limit]

    def to_context(self, text: str, max_skills: int = 5) -> str:
        """Ğ¡Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ½Ğ°Ğ²Ñ‹ĞºĞ¾Ğ² Ğ´Ğ»Ñ LLM."""
        matching = self.find_matching(text)[:max_skills]
        if not matching:
            return ""

        lines = ["ğŸ“ Ğ Ğ•Ğ›Ğ•Ğ’ĞĞĞ¢ĞĞ«Ğ• ĞĞĞ’Ğ«ĞšĞ˜ (Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ğ¸Ñ…):"]
        for skill in matching:
            lines.append(
                f"  â€¢ {skill.name} (ÑƒÑĞ¿ĞµÑ… {skill.success_rate:.0%}): "
                f"{skill.strategy}"
            )

        return "\n".join(lines)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FAILURE LEARNING v2 â€” ĞŸÑ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ñ…
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@dataclass
class FailureRecord:
    """Ğ—Ğ°Ğ¿Ğ¸ÑÑŒ Ğ¾Ğ± Ğ¾ÑˆĞ¸Ğ±ĞºĞµ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ."""
    id: str = ""
    error_type: str = ""           # classification: tool_error, logic_error, data_error
    query: str = ""                # Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ñ€Ğ¸Ğ²Ñ‘Ğ» Ğº Ğ¾ÑˆĞ¸Ğ±ĞºĞµ
    error_message: str = ""
    context: str = ""              # ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸
    correction: str = ""           # ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ
    severity: str = "medium"       # low, medium, high, critical
    tool_involved: str = ""        # ĞšĞ°ĞºĞ¾Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ ÑĞ»Ğ¾Ğ¼Ğ°Ğ»ÑÑ
    timestamp: datetime = field(default_factory=datetime.utcnow)
    applied_count: int = 0         # Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ€Ğ°Ğ· ÑƒÑ€Ğ¾Ğº Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ñ‘Ğ½

    def to_dict(self) -> dict:
        return {
            "error_type": self.error_type,
            "query": self.query[:100],
            "error": self.error_message[:200],
            "correction": self.correction[:200],
            "severity": self.severity,
            "tool": self.tool_involved,
            "applied": self.applied_count,
        }


class FailureLearningEngine:
    """
    Ğ”Ğ²Ğ¸Ğ¶Ğ¾Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ñ….

    ĞŸÑ€Ğ¾Ñ†ĞµÑÑ:
    1. ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ¾ÑˆĞ»Ğ° â†’ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµĞ¼
    2. ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ñ
    3. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² base
    4. ĞŸÑ€Ğ¸ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶ĞµĞ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ â†’ Ğ¿Ğ¾Ğ´Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ ÑƒÑ€Ğ¾ĞºĞ¸
    5. ĞÑ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°ĞµĞ¼: Ğ¿Ğ¾Ğ¼Ğ¾Ğ³ Ğ»Ğ¸ ÑƒÑ€Ğ¾Ğº?
    """

    # ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ¿Ğ¾ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ°Ğ¼
    ERROR_PATTERNS: dict[str, str] = {
        r"timeout|timed out": "timeout_error",
        r"not found|404|Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½": "not_found_error",
        r"permission|403|Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰ĞµĞ½": "permission_error",
        r"rate.?limit|429|ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼.?Ñ‡Ğ°ÑÑ‚Ğ¾": "rate_limit_error",
        r"parse|json|syntax": "parse_error",
        r"network|connection|connect": "network_error",
        r"memory|overflow|out.?of": "resource_error",
        r"invalid|validation|Ğ½ĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½": "validation_error",
    }

    def __init__(self):
        self._failures: list[FailureRecord] = []
        self._failure_counter: int = 0

    def record_failure(
        self,
        query: str,
        error_message: str,
        context: str = "",
        correction: str = "",
        tool_involved: str = "",
        severity: str = "medium",
    ) -> FailureRecord:
        """Ğ—Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ."""
        self._failure_counter += 1

        # ĞĞ²Ñ‚Ğ¾ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ
        error_type = self._classify_error(error_message)

        record = FailureRecord(
            id=f"fail_{self._failure_counter}",
            error_type=error_type,
            query=query,
            error_message=error_message,
            context=context,
            correction=correction,
            severity=severity,
            tool_involved=tool_involved,
        )

        self._failures.append(record)

        # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€
        if len(self._failures) > 500:
            # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ğ½Ğ¸Ğ·ĞºĞ¾Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ½Ñ‹Ğµ
            self._failures = sorted(
                self._failures,
                key=lambda f: (
                    f.severity == "critical",
                    f.severity == "high",
                    f.applied_count > 0,
                    f.timestamp,
                ),
                reverse=True,
            )[:300]

        logger.debug(f"Failure recorded: {error_type} for Â«{query[:50]}Â»")
        return record

    def get_relevant_lessons(
        self,
        query: str,
        tool: str = "",
        limit: int = 3,
    ) -> list[FailureRecord]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğµ ÑƒÑ€Ğ¾ĞºĞ¸ Ğ´Ğ»Ñ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°."""
        if not self._failures:
            return []

        scored: list[tuple[float, FailureRecord]] = []

        query_words = set(re.findall(r'\w{3,}', query.lower()))

        for record in self._failures:
            score = 0.0

            # Ğ¡Ğ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°
            if tool and record.tool_involved == tool:
                score += 0.4

            # Ğ¡Ğ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ ÑĞ»Ğ¾Ğ² Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°
            record_words = set(re.findall(r'\w{3,}', record.query.lower()))
            if query_words and record_words:
                overlap = len(query_words & record_words) / \
                    max(len(query_words), 1)
                score += overlap * 0.3

            # Ğ¢Ğ¸Ğ¿ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ (Ñ‡Ğ°ÑÑ‚Ñ‹Ğµ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ²Ğ°Ğ¶Ğ½ĞµĞµ)
            type_counts = Counter(f.error_type for f in self._failures)
            type_freq = type_counts.get(
                record.error_type, 0) / len(self._failures)
            score += type_freq * 0.2

            # Severity
            severity_weights = {"critical": 0.3,
                                "high": 0.2, "medium": 0.1, "low": 0.05}
            score += severity_weights.get(record.severity, 0.1)

            # ĞĞ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ğ¸
            if record.correction:
                score += 0.2

            if score > 0.2:
                scored.append((score, record))

        # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸
        scored.sort(key=lambda x: x[0], reverse=True)

        results = [record for _, record in scored[:limit]]

        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ applied_count
        for r in results:
            r.applied_count += 1

        return results

    def to_context(self, query: str, tool: str = "") -> str:
        """Ğ¡Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ ÑƒÑ€Ğ¾ĞºĞ¾Ğ² Ğ´Ğ»Ñ LLM."""
        lessons = self.get_relevant_lessons(query, tool)
        if not lessons:
            return ""

        lines = ["âš ï¸ Ğ£Ğ ĞĞšĞ˜ Ğ˜Ğ— ĞŸĞ ĞĞ¨Ğ›Ğ«Ğ¥ ĞĞ¨Ğ˜Ğ‘ĞĞš (ĞĞ• ĞŸĞĞ’Ğ¢ĞĞ Ğ¯Ğ™):"]
        for lesson in lessons:
            lines.append(
                f"  â€¢ [{lesson.error_type}] {lesson.error_message[:100]}")
            if lesson.correction:
                lines.append(f"    â†’ ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾: {lesson.correction[:100]}")

        return "\n".join(lines)

    def _classify_error(self, error_message: str) -> str:
        """ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ."""
        lower = error_message.lower()
        for pattern, error_type in self.ERROR_PATTERNS.items():
            if re.search(pattern, lower):
                return error_type
        return "unknown_error"

    @property
    def total_failures(self) -> int:
        return len(self._failures)

    def get_stats(self) -> dict[str, Any]:
        """Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº."""
        if not self._failures:
            return {"total": 0, "by_type": {}, "by_severity": {}}

        return {
            "total": len(self._failures),
            "by_type": dict(Counter(f.error_type for f in self._failures)),
            "by_severity": dict(Counter(f.severity for f in self._failures)),
            "with_correction": sum(1 for f in self._failures if f.correction),
            "applied": sum(1 for f in self._failures if f.applied_count > 0),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STRATEGIC MEMORY â€” ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ¸ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@dataclass
class StrategicPattern:
    """Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½, Ğ²Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ¼."""
    id: str = ""
    name: str = ""
    description: str = ""
    evidence: list[str] = field(default_factory=list)  # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹
    confidence: float = 0.5
    category: str = ""  # user_preference, business_pattern, workflow
    created_at: datetime = field(default_factory=datetime.utcnow)
    updated_at: datetime = field(default_factory=datetime.utcnow)

    def to_dict(self) -> dict:
        return {
            "name": self.name,
            "description": self.description,
            "confidence": round(self.confidence, 2),
            "category": self.category,
            "evidence_count": len(self.evidence),
        }


class StrategicMemory:
    """
    Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ â€” Ğ²Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¸ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ².

    ĞĞ³ĞµĞ½Ñ‚ ÑƒÑ‡Ğ¸Ñ‚ÑÑ:
    - ĞŸÑ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ (Ğ²ÑĞµĞ³Ğ´Ğ° Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ X)
    - Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ (Ğ·Ğ°ĞºĞ°Ğ·Ñ‹ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ğ½Ğ° ÑÑƒĞ¼Ğ¼Ñƒ Y)
    - Workflow (Ğ¿Ğ¾ÑĞ»Ğµ X Ğ²ÑĞµĞ³Ğ´Ğ° Ğ´ĞµĞ»Ğ°ĞµÑ‚ Y)
    - Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ (Ğ¿Ğ¾ Ğ¿Ğ¾Ğ½ĞµĞ´ĞµĞ»ÑŒĞ½Ğ¸ĞºĞ°Ğ¼ Ğ²ÑĞµĞ³Ğ´Ğ° Z)
    """

    def __init__(self):
        self._patterns: dict[str, StrategicPattern] = {}
        self._observations: list[dict[str, Any]] = []
        self._pattern_counter: int = 0

    def add_observation(
        self,
        action: str,
        context: str = "",
        result: str = "",
        metadata: dict[str, Any] | None = None,
    ) -> None:
        """Ğ—Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ²."""
        self._observations.append({
            "action": action,
            "context": context,
            "result": result,
            "metadata": metadata or {},
            "timestamp": datetime.utcnow().isoformat(),
        })

        # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼
        if len(self._observations) > 1000:
            self._observations = self._observations[-500:]

    def extract_patterns(self, min_occurrences: int = 3) -> list[StrategicPattern]:
        """
        Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ¸Ğ· Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ğ¹.

        ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ ÑĞ²Ñ€Ğ¸ÑÑ‚Ğ¸ĞºĞ°: Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ action + Ğ¸Ñ‰ĞµĞ¼ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ñ‹.
        """
        if len(self._observations) < min_occurrences:
            return []

        # Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸ÑĞ¼
        action_groups: dict[str, list[dict]] = defaultdict(list)
        for obs in self._observations:
            action_groups[obs["action"]].append(obs)

        new_patterns: list[StrategicPattern] = []

        for action, group in action_groups.items():
            if len(group) >= min_occurrences:
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ğ½ĞµÑ‚ Ğ»Ğ¸ ÑƒĞ¶Ğµ Ñ‚Ğ°ĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ°
                existing = self._find_pattern_by_action(action)
                if existing:
                    existing.evidence.append(
                        f"ĞŸĞ¾Ğ²Ñ‚Ğ¾Ñ€ĞµĞ½Ğ¾ x{len(group)}"
                    )
                    existing.confidence = min(1.0, existing.confidence + 0.05)
                    existing.updated_at = datetime.utcnow()
                else:
                    self._pattern_counter += 1
                    pattern = StrategicPattern(
                        id=f"pat_{self._pattern_counter}",
                        name=f"ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½: {action}",
                        description=f"Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ '{action}' Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€ÑĞµÑ‚ÑÑ {len(group)} Ñ€Ğ°Ğ·",
                        evidence=[obs.get("context", "")[:100]
                                  for obs in group[:5]],
                        confidence=min(1.0, len(group) / 10),
                        category="workflow",
                    )
                    self._patterns[pattern.id] = pattern
                    new_patterns.append(pattern)

        return new_patterns

    def get_relevant_patterns(self, context: str, limit: int = 5) -> list[StrategicPattern]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹."""
        if not self._patterns:
            return []

        context_words = set(re.findall(r'\w{3,}', context.lower()))

        scored: list[tuple[float, StrategicPattern]] = []
        for pattern in self._patterns.values():
            pattern_words = set(re.findall(
                r'\w{3,}',
                f"{pattern.name} {pattern.description}".lower()
            ))

            if not pattern_words:
                continue

            overlap = len(context_words & pattern_words) / \
                max(len(pattern_words), 1)
            score = overlap * pattern.confidence

            if score > 0.1:
                scored.append((score, pattern))

        scored.sort(key=lambda x: x[0], reverse=True)
        return [p for _, p in scored[:limit]]

    def to_context(self, query: str) -> str:
        """Ğ¡Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ² Ğ´Ğ»Ñ LLM."""
        patterns = self.get_relevant_patterns(query)
        if not patterns:
            return ""

        lines = ["ğŸ“Š Ğ¡Ğ¢Ğ ĞĞ¢Ğ•Ğ“Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• ĞŸĞĞ¢Ğ¢Ğ•Ğ ĞĞ«:"]
        for p in patterns:
            lines.append(f"  â€¢ {p.name} (ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ {p.confidence:.0%})")
            if p.description:
                lines.append(f"    {p.description[:100]}")

        return "\n".join(lines)

    def _find_pattern_by_action(self, action: str) -> StrategicPattern | None:
        """ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½ Ğ¿Ğ¾ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ."""
        for p in self._patterns.values():
            if action.lower() in p.name.lower():
                return p
        return None

    @property
    def pattern_count(self) -> int:
        return len(self._patterns)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONTEXT WINDOW OPTIMIZER â€” ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° LLM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class ContextWindowOptimizer:
    """
    ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¾ĞºĞ½Ğ° LLM.

    Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ°: ÑƒĞ¼ĞµÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸
    Ğ² Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ¾Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ¾Ğµ Ğ¾ĞºĞ½Ğ¾.

    ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ñ‹:
    1. System prompt + tools (Ğ½ĞµĞ¸Ğ·Ğ¼ĞµĞ½Ğ½Ğ¾)
    2. Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
    3. Ğ ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğµ Ğ½Ğ°Ğ²Ñ‹ĞºĞ¸ Ğ¸ ÑƒÑ€Ğ¾ĞºĞ¸
    4. ĞĞµĞ´Ğ°Ğ²Ğ½ÑÑ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ (Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ)
    5. Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹
    6. ĞĞ±Ñ‰Ğ¸Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ
    """

    # Ğ‘ÑĞ´Ğ¶ĞµÑ‚ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ±Ğ»Ğ¾ĞºĞ° (Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾)
    DEFAULT_BUDGET: dict[str, int] = {
        "system": 3000,
        "tools": 2000,
        "query": 500,
        "skills": 500,
        "failures": 500,
        "memory": 1500,
        "patterns": 300,
        "history": 2000,
    }

    def __init__(self, max_tokens: int = 8000):
        self.max_chars = max_tokens * 3  # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ 3 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ° Ğ½Ğ° Ñ‚Ğ¾ĞºĞµĞ½
        self.budget = dict(self.DEFAULT_BUDGET)

    def optimize(
        self,
        blocks: dict[str, str],
        priorities: dict[str, int] | None = None,
    ) -> dict[str, str]:
        """
        ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ±Ğ»Ğ¾ĞºĞ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°.

        Args:
            blocks: {"system": "...", "memory": "...", ...}
            priorities: {"system": 10, "memory": 5, ...}

        Returns:
            ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ±Ğ»Ğ¾ĞºĞ¸ (Ğ¾Ğ±Ñ€ĞµĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸)
        """
        priorities = priorities or {
            "system": 10,
            "tools": 9,
            "query": 8,
            "skills": 7,
            "failures": 6,
            "memory": 5,
            "patterns": 4,
            "history": 3,
        }

        # ĞĞ±Ñ‰Ğ¸Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€
        total = sum(len(v) for v in blocks.values())

        if total <= self.max_chars:
            return blocks  # Ğ’ÑÑ‘ Ğ¿Ğ¾Ğ¼ĞµÑ‰Ğ°ĞµÑ‚ÑÑ

        # ĞÑƒĞ¶Ğ½Ğ¾ ÑƒÑ€ĞµĞ·Ğ°Ñ‚ÑŒ â€” Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ñ Ğ½Ğ¸Ğ·ĞºĞ¾Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ½Ñ‹Ñ…
        sorted_blocks = sorted(
            blocks.items(),
            key=lambda x: priorities.get(x[0], 0),
        )

        remaining = self.max_chars
        result: dict[str, str] = {}

        # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ²Ñ‹Ğ´ĞµĞ»ÑĞµĞ¼ Ğ¼ĞµÑÑ‚Ğ¾ Ğ´Ğ»Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ½Ñ‹Ñ…
        for name, content in reversed(sorted_blocks):
            budget = self.budget.get(name, 500)
            actual = min(len(content), budget)
            remaining -= actual

        # Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼
        remaining = self.max_chars
        for name, content in reversed(sorted_blocks):
            budget = self.budget.get(name, 500)

            if remaining <= 0:
                result[name] = ""
                continue

            if len(content) <= budget:
                result[name] = content
                remaining -= len(content)
            else:
                # ĞĞ±Ñ€ĞµĞ·Ğ°ĞµĞ¼
                result[name] = content[:min(budget, remaining)] + "..."
                remaining -= min(budget, remaining)

        return result

    def estimate_tokens(self, text: str) -> int:
        """ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²."""
        # ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ ÑĞ²Ñ€Ğ¸ÑÑ‚Ğ¸ĞºĞ°: ~3 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ° Ğ½Ğ° Ñ‚Ğ¾ĞºĞµĞ½ Ğ´Ğ»Ñ Ñ€ÑƒÑÑĞºĞ¾Ğ³Ğ¾
        return len(text) // 3


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MEMORY V2 ENGINE â€” ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class MemoryV2Engine:
    """
    ĞŸĞ°Ğ¼ÑÑ‚ÑŒ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾ĞºĞ¾Ğ»ĞµĞ½Ğ¸Ñ.

    ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚:
    - Skill Library (Ğ½Ğ°Ğ²Ñ‹ĞºĞ¸)
    - Failure Learning (ÑƒÑ€Ğ¾ĞºĞ¸ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº)
    - Strategic Memory (Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹)
    - Context Optimizer (Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¾ĞºĞ½Ğ°)
    """

    def __init__(self):
        self.skills = SkillLibrary()
        self.failures = FailureLearningEngine()
        self.strategic = StrategicMemory()
        self.optimizer = ContextWindowOptimizer()

    def get_full_context(self, query: str, tool: str = "") -> str:
        """
        ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°.

        Ğ’ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚: Ğ½Ğ°Ğ²Ñ‹ĞºĞ¸ + ÑƒÑ€Ğ¾ĞºĞ¸ + Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹.
        """
        parts = []

        skills_ctx = self.skills.to_context(query)
        if skills_ctx:
            parts.append(skills_ctx)

        failures_ctx = self.failures.to_context(query, tool)
        if failures_ctx:
            parts.append(failures_ctx)

        patterns_ctx = self.strategic.to_context(query)
        if patterns_ctx:
            parts.append(patterns_ctx)

        return "\n\n".join(parts)

    def record_success(
        self,
        query: str,
        tools_used: list[str],
        strategy: str = "",
    ) -> None:
        """Ğ—Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ."""
        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ½Ğ°Ğ²Ñ‹ĞºĞ¸
        for skill in self.skills.find_matching(query):
            self.skills.record_usage(skill.id, success=True)

        # ĞĞ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
        self.strategic.add_observation(
            action=f"success:{','.join(tools_used)}",
            context=query,
            result="success",
        )

    def record_failure(
        self,
        query: str,
        error: str,
        tool: str = "",
        correction: str = "",
    ) -> None:
        """Ğ—Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ."""
        self.failures.record_failure(
            query=query,
            error_message=error,
            tool_involved=tool,
            correction=correction,
        )

        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ½Ğ°Ğ²Ñ‹ĞºĞ¸
        for skill in self.skills.find_matching(query):
            self.skills.record_usage(skill.id, success=False)

    def learn_skill(
        self,
        name: str,
        pattern: str,
        strategy: str,
        tools: list[str] | None = None,
    ) -> Skill:
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ½Ğ°Ğ²Ñ‹Ğº."""
        return self.skills.add_skill(
            name=name,
            pattern=pattern,
            strategy=strategy,
            tools_used=tools or [],
        )

    def analyze_patterns(self) -> list[StrategicPattern]:
        """Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ²."""
        return self.strategic.extract_patterns()

    def get_stats(self) -> dict[str, Any]:
        """Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ v2."""
        return {
            "skills": self.skills.count,
            "failures": self.failures.total_failures,
            "patterns": self.strategic.pattern_count,
            "failure_stats": self.failures.get_stats(),
            "top_skills": [
                s.to_dict() for s in self.skills.get_top_skills(5)
            ],
        }


# â”€â”€â”€ Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞºĞ·ĞµĞ¼Ğ¿Ğ»ÑÑ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

memory_v2 = MemoryV2Engine()
